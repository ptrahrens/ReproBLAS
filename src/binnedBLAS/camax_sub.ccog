#include <stdlib.h>
#include <math.h>

#include "../config.h"
#include "../common/common.h"
#include "binnedBLAS.h"

/*[[[cog
import cog
import generate
import dataTypes
import amax
import vectorizations

code_block = generate.CodeBlock()
vectorizations.conditionally_include_vectorizations(code_block)
cog.out(str(code_block))
]]]*/
#if (defined(__AVX__) && !defined(reproBLAS_no__AVX__))
  #include <immintrin.h>

#elif (defined(__SSE2__) && !defined(reproBLAS_no__SSE2__))
  #include <emmintrin.h>

#else


#endif
//[[[end]]]


/**
 * @internal
 * @brief  Find maximum magnitude in vector of complex single precision
 *
 * Returns the magnitude of the element of maximum magnitude in an array.
 *
 * @param N vector length
 * @param X complex single precision vector
 * @param incX X vector stride (use every incX'th element)
 * @param amax scalar return
 *
 * @author Willow Ahrens
 * @date   15 Jan 2016
 */
void binnedBLAS_camax_sub(const int N, const void *X, const int incX, void *amax) {
  const float *x = (const float*)X;
  /*[[[cog
  cog.out(generate.generate(amax.AMax(dataTypes.FloatComplex, "N", "x", "incX", "amax"), cog.inFile, args, params, mode))
  ]]]*/
  #if (defined(__AVX__) && !defined(reproBLAS_no__AVX__))
    __m256 abs_mask_tmp;
    {
      __m256 tmp;
      tmp = _mm256_set1_ps(1);
      abs_mask_tmp = _mm256_set1_ps(-1);
      abs_mask_tmp = _mm256_xor_ps(abs_mask_tmp, tmp);
      tmp = _mm256_cmp_ps(tmp, tmp, 0);
      abs_mask_tmp = _mm256_xor_ps(abs_mask_tmp, tmp);
    }
    float max_buffer_tmp[8] __attribute__((aligned(32))); (void)max_buffer_tmp;

    int i;

    __m256 x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7;
    __m256 m_0;
    m_0 = _mm256_setzero_ps();

    if(incX == 1){

      for(i = 0; i + 32 <= N; i += 32, x += 64){
        x_0 = _mm256_and_ps(_mm256_loadu_ps(((float*)x)), abs_mask_tmp);
        x_1 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 8), abs_mask_tmp);
        x_2 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 16), abs_mask_tmp);
        x_3 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 24), abs_mask_tmp);
        x_4 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 32), abs_mask_tmp);
        x_5 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 40), abs_mask_tmp);
        x_6 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 48), abs_mask_tmp);
        x_7 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 56), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        m_0 = _mm256_max_ps(m_0, x_1);
        m_0 = _mm256_max_ps(m_0, x_2);
        m_0 = _mm256_max_ps(m_0, x_3);
        m_0 = _mm256_max_ps(m_0, x_4);
        m_0 = _mm256_max_ps(m_0, x_5);
        m_0 = _mm256_max_ps(m_0, x_6);
        m_0 = _mm256_max_ps(m_0, x_7);
      }
      if(i + 16 <= N){
        x_0 = _mm256_and_ps(_mm256_loadu_ps(((float*)x)), abs_mask_tmp);
        x_1 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 8), abs_mask_tmp);
        x_2 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 16), abs_mask_tmp);
        x_3 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 24), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        m_0 = _mm256_max_ps(m_0, x_1);
        m_0 = _mm256_max_ps(m_0, x_2);
        m_0 = _mm256_max_ps(m_0, x_3);
        i += 16, x += 32;
      }
      if(i + 8 <= N){
        x_0 = _mm256_and_ps(_mm256_loadu_ps(((float*)x)), abs_mask_tmp);
        x_1 = _mm256_and_ps(_mm256_loadu_ps(((float*)x) + 8), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        m_0 = _mm256_max_ps(m_0, x_1);
        i += 8, x += 16;
      }
      if(i + 4 <= N){
        x_0 = _mm256_and_ps(_mm256_loadu_ps(((float*)x)), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        i += 4, x += 8;
      }
      if(i < N){
        x_0 = _mm256_and_ps((__m256)_mm256_set_pd(0, (N - i)>2?((double*)((float*)x))[2]:0, (N - i)>1?((double*)((float*)x))[1]:0, ((double*)((float*)x))[0]), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        x += ((N - i) * 2);
      }
    }else{

      for(i = 0; i + 32 <= N; i += 32, x += (incX * 64)){
        x_0 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)], ((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        x_1 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 14) + 1)], ((float*)x)[(incX * 14)], ((float*)x)[((incX * 12) + 1)], ((float*)x)[(incX * 12)], ((float*)x)[((incX * 10) + 1)], ((float*)x)[(incX * 10)], ((float*)x)[((incX * 8) + 1)], ((float*)x)[(incX * 8)]), abs_mask_tmp);
        x_2 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 22) + 1)], ((float*)x)[(incX * 22)], ((float*)x)[((incX * 20) + 1)], ((float*)x)[(incX * 20)], ((float*)x)[((incX * 18) + 1)], ((float*)x)[(incX * 18)], ((float*)x)[((incX * 16) + 1)], ((float*)x)[(incX * 16)]), abs_mask_tmp);
        x_3 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 30) + 1)], ((float*)x)[(incX * 30)], ((float*)x)[((incX * 28) + 1)], ((float*)x)[(incX * 28)], ((float*)x)[((incX * 26) + 1)], ((float*)x)[(incX * 26)], ((float*)x)[((incX * 24) + 1)], ((float*)x)[(incX * 24)]), abs_mask_tmp);
        x_4 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 38) + 1)], ((float*)x)[(incX * 38)], ((float*)x)[((incX * 36) + 1)], ((float*)x)[(incX * 36)], ((float*)x)[((incX * 34) + 1)], ((float*)x)[(incX * 34)], ((float*)x)[((incX * 32) + 1)], ((float*)x)[(incX * 32)]), abs_mask_tmp);
        x_5 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 46) + 1)], ((float*)x)[(incX * 46)], ((float*)x)[((incX * 44) + 1)], ((float*)x)[(incX * 44)], ((float*)x)[((incX * 42) + 1)], ((float*)x)[(incX * 42)], ((float*)x)[((incX * 40) + 1)], ((float*)x)[(incX * 40)]), abs_mask_tmp);
        x_6 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 54) + 1)], ((float*)x)[(incX * 54)], ((float*)x)[((incX * 52) + 1)], ((float*)x)[(incX * 52)], ((float*)x)[((incX * 50) + 1)], ((float*)x)[(incX * 50)], ((float*)x)[((incX * 48) + 1)], ((float*)x)[(incX * 48)]), abs_mask_tmp);
        x_7 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 62) + 1)], ((float*)x)[(incX * 62)], ((float*)x)[((incX * 60) + 1)], ((float*)x)[(incX * 60)], ((float*)x)[((incX * 58) + 1)], ((float*)x)[(incX * 58)], ((float*)x)[((incX * 56) + 1)], ((float*)x)[(incX * 56)]), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        m_0 = _mm256_max_ps(m_0, x_1);
        m_0 = _mm256_max_ps(m_0, x_2);
        m_0 = _mm256_max_ps(m_0, x_3);
        m_0 = _mm256_max_ps(m_0, x_4);
        m_0 = _mm256_max_ps(m_0, x_5);
        m_0 = _mm256_max_ps(m_0, x_6);
        m_0 = _mm256_max_ps(m_0, x_7);
      }
      if(i + 16 <= N){
        x_0 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)], ((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        x_1 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 14) + 1)], ((float*)x)[(incX * 14)], ((float*)x)[((incX * 12) + 1)], ((float*)x)[(incX * 12)], ((float*)x)[((incX * 10) + 1)], ((float*)x)[(incX * 10)], ((float*)x)[((incX * 8) + 1)], ((float*)x)[(incX * 8)]), abs_mask_tmp);
        x_2 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 22) + 1)], ((float*)x)[(incX * 22)], ((float*)x)[((incX * 20) + 1)], ((float*)x)[(incX * 20)], ((float*)x)[((incX * 18) + 1)], ((float*)x)[(incX * 18)], ((float*)x)[((incX * 16) + 1)], ((float*)x)[(incX * 16)]), abs_mask_tmp);
        x_3 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 30) + 1)], ((float*)x)[(incX * 30)], ((float*)x)[((incX * 28) + 1)], ((float*)x)[(incX * 28)], ((float*)x)[((incX * 26) + 1)], ((float*)x)[(incX * 26)], ((float*)x)[((incX * 24) + 1)], ((float*)x)[(incX * 24)]), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        m_0 = _mm256_max_ps(m_0, x_1);
        m_0 = _mm256_max_ps(m_0, x_2);
        m_0 = _mm256_max_ps(m_0, x_3);
        i += 16, x += (incX * 32);
      }
      if(i + 8 <= N){
        x_0 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)], ((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        x_1 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 14) + 1)], ((float*)x)[(incX * 14)], ((float*)x)[((incX * 12) + 1)], ((float*)x)[(incX * 12)], ((float*)x)[((incX * 10) + 1)], ((float*)x)[(incX * 10)], ((float*)x)[((incX * 8) + 1)], ((float*)x)[(incX * 8)]), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        m_0 = _mm256_max_ps(m_0, x_1);
        i += 8, x += (incX * 16);
      }
      if(i + 4 <= N){
        x_0 = _mm256_and_ps(_mm256_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)], ((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        i += 4, x += (incX * 8);
      }
      if(i < N){
        x_0 = _mm256_and_ps((__m256)_mm256_set_pd(0, (N - i)>2?((double*)((float*)x))[(incX * 2)]:0, (N - i)>1?((double*)((float*)x))[incX]:0, ((double*)((float*)x))[0]), abs_mask_tmp);
        m_0 = _mm256_max_ps(m_0, x_0);
        x += (incX * (N - i) * 2);
      }
    }
    _mm256_store_ps(max_buffer_tmp, m_0);
    max_buffer_tmp[0] = (max_buffer_tmp[0] > max_buffer_tmp[2] ? max_buffer_tmp[0]: max_buffer_tmp[2]);
    max_buffer_tmp[1] = (max_buffer_tmp[1] > max_buffer_tmp[3] ? max_buffer_tmp[1]: max_buffer_tmp[3]);
    max_buffer_tmp[0] = (max_buffer_tmp[0] > max_buffer_tmp[4] ? max_buffer_tmp[0]: max_buffer_tmp[4]);
    max_buffer_tmp[1] = (max_buffer_tmp[1] > max_buffer_tmp[5] ? max_buffer_tmp[1]: max_buffer_tmp[5]);
    max_buffer_tmp[0] = (max_buffer_tmp[0] > max_buffer_tmp[6] ? max_buffer_tmp[0]: max_buffer_tmp[6]);
    max_buffer_tmp[1] = (max_buffer_tmp[1] > max_buffer_tmp[7] ? max_buffer_tmp[1]: max_buffer_tmp[7]);
    ((float*)amax)[0] = max_buffer_tmp[0];
    ((float*)amax)[1] = max_buffer_tmp[1];

  #elif (defined(__SSE2__) && !defined(reproBLAS_no__SSE2__))
    __m128 abs_mask_tmp;
    {
      __m128 tmp;
      tmp = _mm_set1_ps(1);
      abs_mask_tmp = _mm_set1_ps(-1);
      abs_mask_tmp = _mm_xor_ps(abs_mask_tmp, tmp);
      tmp = _mm_cmpeq_ps(tmp, tmp);
      abs_mask_tmp = _mm_xor_ps(abs_mask_tmp, tmp);
    }
    float max_buffer_tmp[4] __attribute__((aligned(16))); (void)max_buffer_tmp;

    int i;

    __m128 x_0, x_1, x_2, x_3, x_4, x_5;
    __m128 m_0;
    m_0 = _mm_setzero_ps();

    if(incX == 1){

      for(i = 0; i + 12 <= N; i += 12, x += 24){
        x_0 = _mm_and_ps(_mm_loadu_ps(((float*)x)), abs_mask_tmp);
        x_1 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 4), abs_mask_tmp);
        x_2 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 8), abs_mask_tmp);
        x_3 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 12), abs_mask_tmp);
        x_4 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 16), abs_mask_tmp);
        x_5 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 20), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        m_0 = _mm_max_ps(m_0, x_1);
        m_0 = _mm_max_ps(m_0, x_2);
        m_0 = _mm_max_ps(m_0, x_3);
        m_0 = _mm_max_ps(m_0, x_4);
        m_0 = _mm_max_ps(m_0, x_5);
      }
      if(i + 8 <= N){
        x_0 = _mm_and_ps(_mm_loadu_ps(((float*)x)), abs_mask_tmp);
        x_1 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 4), abs_mask_tmp);
        x_2 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 8), abs_mask_tmp);
        x_3 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 12), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        m_0 = _mm_max_ps(m_0, x_1);
        m_0 = _mm_max_ps(m_0, x_2);
        m_0 = _mm_max_ps(m_0, x_3);
        i += 8, x += 16;
      }
      if(i + 4 <= N){
        x_0 = _mm_and_ps(_mm_loadu_ps(((float*)x)), abs_mask_tmp);
        x_1 = _mm_and_ps(_mm_loadu_ps(((float*)x) + 4), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        m_0 = _mm_max_ps(m_0, x_1);
        i += 4, x += 8;
      }
      if(i + 2 <= N){
        x_0 = _mm_and_ps(_mm_loadu_ps(((float*)x)), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        i += 2, x += 4;
      }
      if(i < N){
        x_0 = _mm_and_ps(_mm_set_ps(0, 0, ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        x += ((N - i) * 2);
      }
    }else{

      for(i = 0; i + 12 <= N; i += 12, x += (incX * 24)){
        x_0 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        x_1 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)]), abs_mask_tmp);
        x_2 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 10) + 1)], ((float*)x)[(incX * 10)], ((float*)x)[((incX * 8) + 1)], ((float*)x)[(incX * 8)]), abs_mask_tmp);
        x_3 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 14) + 1)], ((float*)x)[(incX * 14)], ((float*)x)[((incX * 12) + 1)], ((float*)x)[(incX * 12)]), abs_mask_tmp);
        x_4 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 18) + 1)], ((float*)x)[(incX * 18)], ((float*)x)[((incX * 16) + 1)], ((float*)x)[(incX * 16)]), abs_mask_tmp);
        x_5 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 22) + 1)], ((float*)x)[(incX * 22)], ((float*)x)[((incX * 20) + 1)], ((float*)x)[(incX * 20)]), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        m_0 = _mm_max_ps(m_0, x_1);
        m_0 = _mm_max_ps(m_0, x_2);
        m_0 = _mm_max_ps(m_0, x_3);
        m_0 = _mm_max_ps(m_0, x_4);
        m_0 = _mm_max_ps(m_0, x_5);
      }
      if(i + 8 <= N){
        x_0 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        x_1 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)]), abs_mask_tmp);
        x_2 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 10) + 1)], ((float*)x)[(incX * 10)], ((float*)x)[((incX * 8) + 1)], ((float*)x)[(incX * 8)]), abs_mask_tmp);
        x_3 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 14) + 1)], ((float*)x)[(incX * 14)], ((float*)x)[((incX * 12) + 1)], ((float*)x)[(incX * 12)]), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        m_0 = _mm_max_ps(m_0, x_1);
        m_0 = _mm_max_ps(m_0, x_2);
        m_0 = _mm_max_ps(m_0, x_3);
        i += 8, x += (incX * 16);
      }
      if(i + 4 <= N){
        x_0 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        x_1 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 6) + 1)], ((float*)x)[(incX * 6)], ((float*)x)[((incX * 4) + 1)], ((float*)x)[(incX * 4)]), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        m_0 = _mm_max_ps(m_0, x_1);
        i += 4, x += (incX * 8);
      }
      if(i + 2 <= N){
        x_0 = _mm_and_ps(_mm_set_ps(((float*)x)[((incX * 2) + 1)], ((float*)x)[(incX * 2)], ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        i += 2, x += (incX * 4);
      }
      if(i < N){
        x_0 = _mm_and_ps(_mm_set_ps(0, 0, ((float*)x)[1], ((float*)x)[0]), abs_mask_tmp);
        m_0 = _mm_max_ps(m_0, x_0);
        x += (incX * (N - i) * 2);
      }
    }
    _mm_store_ps(max_buffer_tmp, m_0);
    max_buffer_tmp[0] = (max_buffer_tmp[0] > max_buffer_tmp[2] ? max_buffer_tmp[0]: max_buffer_tmp[2]);
    max_buffer_tmp[1] = (max_buffer_tmp[1] > max_buffer_tmp[3] ? max_buffer_tmp[1]: max_buffer_tmp[3]);
    ((float*)amax)[0] = max_buffer_tmp[0];
    ((float*)amax)[1] = max_buffer_tmp[1];

  #else
    int i;

    float x_0, x_1;
    float m_0, m_1;
    m_0 = 0;
    m_1 = 0;

    if(incX == 1){

      for(i = 0; i + 1 <= N; i += 1, x += 2){
        x_0 = fabsf(((float*)x)[0]);
        x_1 = fabsf(((float*)x)[1]);
        m_0 = (m_0 > x_0? m_0: x_0);
        m_1 = (m_1 > x_1? m_1: x_1);
      }
    }else{

      for(i = 0; i + 1 <= N; i += 1, x += (incX * 2)){
        x_0 = fabsf(((float*)x)[0]);
        x_1 = fabsf(((float*)x)[1]);
        m_0 = (m_0 > x_0? m_0: x_0);
        m_1 = (m_1 > x_1? m_1: x_1);
      }
    }
    ((float*)amax)[0] = m_0;
    ((float*)amax)[1] = m_1;

  #endif
  //[[[end]]]
}
